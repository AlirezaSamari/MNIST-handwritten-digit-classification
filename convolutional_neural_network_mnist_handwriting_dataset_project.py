# -*- coding: utf-8 -*-
"""Convolutional_Neural_Network_MNIST_Handwriting_Dataset_Project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/164sn3iXwLqIGG_9eKk0grpoi--B7BIEC
"""

import torch
from torch import nn, optim
from torch.utils.data import Dataset, DataLoader
import torchvision.transforms as transforms
import torchvision.datasets as dset
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
if torch.cuda.is_available():
    gpu_name = torch.cuda.get_device_name(0)
    print(f"GPU available: {gpu_name}")
else:
    print("No GPU available.")

IMAGE_SIZE=28
def show_data(sample):
  plt.imshow(sample[0].numpy().reshape((IMAGE_SIZE, IMAGE_SIZE)), cmap='gray')
  plt.title(str(sample[1]))

composes = transforms.Compose([transforms.ToTensor(), transforms.Resize((IMAGE_SIZE, IMAGE_SIZE), antialias=True)])

train_set = dset.MNIST(root='./data', train=True, transform=composes, download = True)
train_set

validation_set = dset.MNIST(root='./data', train=False, transform=composes, download = True)
validation_set

train_loader = DataLoader(train_set, batch_size=128,pin_memory=True)
validation_loader = DataLoader(validation_set, batch_size=5000)

type(train_set[6][1])

fig, axes = plt.subplots(1, 3, figsize=(12, 4))
for i in range(3):
    plt.sca(axes[i])
    show_data(validation_set[i])
plt.show()

"""## Output Size $= \frac{W-F + 2P}{s} + 1$"""

class CNN(nn.Module):
  def __init__(self, out1, out2):
    super(CNN, self).__init__()

    self.cnn1 = nn.Conv2d(in_channels=1, out_channels= out1 ,kernel_size=5, padding=2)
    self.conv1_bn = nn.BatchNorm2d(out1)

    self.maxpool1 = nn.MaxPool2d(kernel_size=2)


    self.cnn2 = nn.Conv2d(in_channels= out1, out_channels=out2, kernel_size=5, stride=1, padding=2)
    self.conv2_bn = nn.BatchNorm2d(out2)

    self.maxpool2 = nn.MaxPool2d(kernel_size=2)


    self.fc1 = nn.Linear(out2*7*7, 10)
    self.fc1_bn = nn.BatchNorm1d(10)
  def forward(self, x):
    x = self.cnn1(x)
    x = self.conv1_bn(x)
    x = torch.relu(x)
    x = self.maxpool1(x)
    x = self.cnn2(x)
    x = self.conv2_bn(x)
    x = torch.relu(x)
    x = self.maxpool2(x)
    x = x.view(x.size(0), -1)
    x = self.fc1(x)
    x = self.fc1_bn(x)
    return x

model = CNN(32, 16).to("cuda")
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr = 0.1)

epochs = 10

def plot_loss_and_accuracy(train_loss_list, validation_loss_list, accuracy_list):
    plt.figure(figsize=(12, 4))
    plt.subplot(1, 2, 1)
    plt.plot(train_loss_list, label="Training Loss")
    plt.xlabel("Epoch")
    plt.ylabel("Loss")
    plt.legend()

    plt.subplot(1, 2, 2)
    plt.plot(accuracy_list, label="Validation Accuracy")
    plt.xlabel("Epoch")
    plt.ylabel("Accuracy")
    plt.legend()

    plt.show()

def train_model(model, train_loader, validation_loader, optimizer, epochs):
    train_loss_list = []
    validation_loss_list = []
    accuracy_list = []
    N_test = len(validation_loader.dataset)

    for epoch in range(epochs):
        for x, y in train_loader:
            optimizer.zero_grad()
            x, y = x.to("cuda"), y.to("cuda")
            yhat_train = model(x)
            loss = criterion(yhat_train, y)
            loss.backward()
            optimizer.step()
            train_loss_list.append(loss.item())

        correct = 0
        with torch.no_grad():
            for x_cv, y_cv in validation_loader:
                model.eval()
                x_cv, y_cv = x_cv.to("cuda"), y_cv.to("cuda")
                yhat_validation = model(x_cv)
                _, yhat_max = torch.max(yhat_validation, 1)
                correct += (yhat_max == y_cv).sum().item()
            accuracy = correct / N_test
            accuracy_list.append(accuracy)
            print(f'Epoch: {epoch} ------ last loss item: {loss} ------ accuracy: {accuracy}')

    plot_loss_and_accuracy(train_loss_list, validation_loss_list, accuracy_list)

train_model(model, train_loader, validation_loader, optimizer, epochs)

class CNN2(nn.Module):
    def __init__(self, out1, out2):
        super(CNN2, self).__init__()

        self.cnn1 = nn.Conv2d(in_channels=1, out_channels=out1, kernel_size=3, padding=1)
        self.conv1_bn = nn.BatchNorm2d(out1)
        self.cnn2 = nn.Conv2d(in_channels=out1, out_channels=out2, kernel_size=3, padding=1)
        self.conv2_bn = nn.BatchNorm2d(out2)
        self.maxpool1 = nn.MaxPool2d(kernel_size=2)
        self.maxpool2 = nn.MaxPool2d(kernel_size=2)
        self.fc1 = nn.Linear(out2 * 7 * 7, 128)
        self.fc1_bn = nn.BatchNorm1d(128)
        self.fc2 = nn.Linear(128, 10)

    def forward(self, x):
        x = self.cnn1(x)
        x = self.conv1_bn(x)
        x = torch.relu(x)
        x = self.maxpool1(x)
        x = self.cnn2(x)
        x = self.conv2_bn(x)
        x = torch.relu(x)
        x = self.maxpool2(x)
        x = x.view(x.size(0), -1)
        x = self.fc1(x)
        x = self.fc1_bn(x)
        x = torch.relu(x)
        x = self.fc2(x)
        return x

model2 = CNN2(32, 64).to("cuda")

optimizer = optim.Adam(model2.parameters(), lr = 0.1)
criterion = nn.CrossEntropyLoss()

train_model(model2, train_loader, validation_loader, optimizer, epochs)